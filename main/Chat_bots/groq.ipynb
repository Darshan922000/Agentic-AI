{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=os.getenv(\"LANGSMITH__PROJECT\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000262E9794680>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000262E8823E30>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model = \"gemma2-9b-it\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I can't share specific details about my training parameters. This information is typically kept confidential by my creators, the Gemma team, to protect the model and prevent misuse.\\n\\nHowever, I can tell you some general things about how large language models like me are trained:\\n\\n* **Massive Datasets:** We are trained on enormous amounts of text data, which allows us to learn patterns in language and understand how words and concepts relate to each other.\\n* **Deep Learning Algorithms:** We use deep learning algorithms, specifically a type of neural network called a transformer, to process and analyze the data.\\n\\n* **Optimization Techniques:**\\n\\nOur training involves complex optimization techniques to adjust the model's parameters and improve its performance.\\n\\n* **Evaluation Metrics:**\\n\\nOur performance is evaluated using various metrics, such as accuracy, fluency, and\\n\\ncomprehensiveness.\\n\\nIf you're interested in learning more about the training of large language models in general, I recommend looking into resources from reputable organizations like Google AI, OpenAI, and the AI Safety Research Institute.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 215, 'prompt_tokens': 14, 'total_tokens': 229, 'completion_time': 0.390909091, 'prompt_time': 0.001901416, 'queue_time': 0.109488579, 'total_time': 0.392810507}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-374c6cb3-ea23-4613-9473-a4dfa18e6b67-0', usage_metadata={'input_tokens': 14, 'output_tokens': 215, 'total_tokens': 229})"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(input=\"what is your training parameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langchain_core.messages import HumanMessage, AIMessage\\n\\nllm.invoke([HumanMessage(content=\"\")])\\n\\n\\nllm.invoke(\\n    [\\n        HumanMessage(content=\"Hi , My name is Darshan and I am a Chief AI Engineer\"),\\n        AIMessage(content=\"Hello Darshan! It\\'s nice to meet you. \\n\\nAs a Chief AI Engineer, what kind of projects are you working on these days?\\n\\n\"),\\n        HumanMessage(content=\"Hey What\\'s my name and what do I do?\")\\n    ]\\n)'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "llm.invoke([HumanMessage(content=\"\")])\n",
    "\n",
    "\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Darshan and I am a Chief AI Engineer\"),\n",
    "        AIMessage(content=\"Hello Darshan! It's nice to meet you. \\n\\nAs a Chief AI Engineer, what kind of projects are you working on these days?\\n\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")''' \n",
    "# It uses past conversation to give next questions answer...See the above cell, we manually adede AIMessage here. What is the dinamic approach...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory # store and manage the conversation's messages in a structured way..\n",
    "from langchain_core.chat_history import BaseChatMessageHistory # adding, retrieving, or clearing messages) for any chat history implementation..\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatMessageHistory    \n",
    "In memory implementation of chat message history. store and manage the conversation's messages in a structured way..\n",
    "\n",
    "\n",
    "### BaseChatMessageHistory     \n",
    "Abstract base class for storing chat message history.\n",
    "Think of an abstract base class like a blueprint for building something. It outlines the required parts (methods and properties) that every finished product (or subclass) should have, but it doesn't build anything on its own. You must create a specific subclass that fills in the details to actually use it.\n",
    "\n",
    "### RunnableWithMessageHistory\n",
    "Runnable that manages chat message history for another Runnable.\n",
    "\n",
    "A chat message history is a sequence of messages that represent a conversation.\n",
    "\n",
    "RunnableWithMessageHistory wraps another Runnable and manages the chat message\n",
    "history for it; it is responsible for reading and updating the chat message\n",
    "history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(llm, get_session_history)\n",
    "\n",
    "# This code sets up a simple session-based chat history system. \n",
    "# It uses a dictionary to store a chat history for each session. \n",
    "# The function checks if a session already has a history, and if not, creates one using the concrete class. \n",
    "# Finally, it wraps a language model with a runnable that automatically handles chat history for each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
      "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0x00000262E96EACA0> history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n"
     ]
    }
   ],
   "source": [
    "print(with_message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note: By default, the Runnable is expected to take a single configuration parameter\\ncalled `session_id` which is a string. This parameter is used to create a new\\nor look up an existing chat message history that matches the given session_id.'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"d9\"}}\n",
    "# The runnable can handle chat histories for multiple sessions, and \n",
    "# the configuration specifies which session ID to use for the current operation.\n",
    "'''Note: By default, the Runnable is expected to take a single configuration parameter\n",
    "called `session_id` which is a string. This parameter is used to create a new\n",
    "or look up an existing chat message history that matches the given session_id.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hi, I am a darshan, a data scientist.\")], config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80})])}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCould you tell me a bit more about what you're working on specifically? For example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, embodied agents, multi-agent systems)\\n* **What tasks are these agents designed to perform?** (e.g., planning, decision-making, interacting with the environment)\\n* **What are some of the challenges you're facing in your work?**\\n\\nI'm eager to learn more about your project!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 96, 'total_tokens': 221, 'completion_time': 0.227272727, 'prompt_time': 0.005262967, 'queue_time': 0.11001534599999999, 'total_time': 0.232535694}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81f1f30c-f6d6-469a-9d85-cb878beb1c6a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 125, 'total_tokens': 221})"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([HumanMessage(content=\"I am working on Agentic AI.\")], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80}), HumanMessage(content='I am working on Agentic AI.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCould you tell me a bit more about what you're working on specifically? For example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, embodied agents, multi-agent systems)\\n* **What tasks are these agents designed to perform?** (e.g., planning, decision-making, interacting with the environment)\\n* **What are some of the challenges you're facing in your work?**\\n\\nI'm eager to learn more about your project!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 96, 'total_tokens': 221, 'completion_time': 0.227272727, 'prompt_time': 0.005262967, 'queue_time': 0.11001534599999999, 'total_time': 0.232535694}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81f1f30c-f6d6-469a-9d85-cb878beb1c6a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 125, 'total_tokens': 221})])}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see the difference b/w two session Id.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Based on our conversation, you are Darshan, a data scientist working on Agentic AI. \\n\\nIs there anything else you'd like to tell me about yourself? I'm always happy to learn more. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 233, 'total_tokens': 283, 'completion_time': 0.090909091, 'prompt_time': 0.009079018, 'queue_time': 0.093239002, 'total_time': 0.099988109}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7992496-1245-4c70-83f3-094cf0c923ad-0', usage_metadata={'input_tokens': 233, 'output_tokens': 50, 'total_tokens': 283})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first example: this session Id we have created and have already given the information...d9\n",
    "config = {\"configurable\": {\"session_id\": \"d9\"}} \n",
    "with_message_history.invoke([HumanMessage(content=\"who Am I?\")], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have personal experiences or memories, so I don't know who you are.\\n\\nTo help me understand, could you tell me a little about yourself? For example:\\n\\n* What are your hobbies?\\n* What do you like to do in your free time?\\n* What are you interested in learning more about?\\n\\n\\nI'm here to chat and help in any way I can! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 13, 'total_tokens': 105, 'completion_time': 0.167272727, 'prompt_time': 0.001887626, 'queue_time': 0.083940956, 'total_time': 0.169160353}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-24195883-91b7-41c3-9125-38fadbbdde57-0', usage_metadata={'input_tokens': 13, 'output_tokens': 92, 'total_tokens': 105})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second is the different, we haven't given any information....d8\n",
    "config = {\"configurable\": {\"session_id\": \"d8\"}}\n",
    "with_message_history.invoke([HumanMessage(content=\"who Am I?\")], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80}), HumanMessage(content='I am working on Agentic AI.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCould you tell me a bit more about what you're working on specifically? For example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, embodied agents, multi-agent systems)\\n* **What tasks are these agents designed to perform?** (e.g., planning, decision-making, interacting with the environment)\\n* **What are some of the challenges you're facing in your work?**\\n\\nI'm eager to learn more about your project!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 96, 'total_tokens': 221, 'completion_time': 0.227272727, 'prompt_time': 0.005262967, 'queue_time': 0.11001534599999999, 'total_time': 0.232535694}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81f1f30c-f6d6-469a-9d85-cb878beb1c6a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 125, 'total_tokens': 221}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on our conversation, you are Darshan, a data scientist working on Agentic AI. \\n\\nIs there anything else you'd like to tell me about yourself? I'm always happy to learn more. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 233, 'total_tokens': 283, 'completion_time': 0.090909091, 'prompt_time': 0.009079018, 'queue_time': 0.093239002, 'total_time': 0.099988109}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7992496-1245-4c70-83f3-094cf0c923ad-0', usage_metadata={'input_tokens': 233, 'output_tokens': 50, 'total_tokens': 283})]),\n",
       " 'd8': InMemoryChatMessageHistory(messages=[HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I don't have personal experiences or memories, so I don't know who you are.\\n\\nTo help me understand, could you tell me a little about yourself? For example:\\n\\n* What are your hobbies?\\n* What do you like to do in your free time?\\n* What are you interested in learning more about?\\n\\n\\nI'm here to chat and help in any way I can! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 13, 'total_tokens': 105, 'completion_time': 0.167272727, 'prompt_time': 0.001887626, 'queue_time': 0.083940956, 'total_time': 0.169160353}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-24195883-91b7-41c3-9125-38fadbbdde57-0', usage_metadata={'input_tokens': 13, 'output_tokens': 92, 'total_tokens': 105})])}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have created session id d8 so see the response..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's a great question! \\n\\nSince I don't have access to personal information about you, I can't tell you who you are.  \\n\\nBut I can help you explore that question!  \\n\\n* **What makes you feel most like yourself?** \\n* **What are some things you're proud of?**\\n* **What are your values and beliefs?**\\n* **What do you want to be remembered for?**\\n\\nThinking about these things might help you discover more about who you are. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 117, 'total_tokens': 233, 'completion_time': 0.210909091, 'prompt_time': 0.005292857, 'queue_time': 0.093278594, 'total_time': 0.216201948}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-eede2b55-5071-4718-991d-9c7fd674c871-0', usage_metadata={'input_tokens': 117, 'output_tokens': 116, 'total_tokens': 233})"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"d8\"}}\n",
    "with_message_history.invoke([HumanMessage(content=\"who Am I?\")], config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt template 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistence, provide answers to the query in short and answer should be as accurate as possible.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello D9! ðŸ‘‹  \\n\\nWhat can I do for you? ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 38, 'total_tokens': 57, 'completion_time': 0.034545455, 'prompt_time': 0.002347354, 'queue_time': 0.10947894400000001, 'total_time': 0.036892809}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7835a251-b64b-41c5-8cb3-6e987a403a25-0', usage_metadata={'input_tokens': 38, 'output_tokens': 19, 'total_tokens': 57})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"Hi My name is D9\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding chain into Runnable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello D9! ðŸ‘‹  How can I help you? ðŸ˜Š  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 38, 'total_tokens': 55, 'completion_time': 0.030909091, 'prompt_time': 0.002340775, 'queue_time': 0.109476953, 'total_time': 0.033249866}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-16e61aca-bbcc-461b-b60b-febadf43eadc-0', usage_metadata={'input_tokens': 38, 'output_tokens': 17, 'total_tokens': 55})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "with_message_history.invoke({\"messages\": [HumanMessage(content=\"Hi My name is D9\")]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a text-only AI, I don't have memory of past conversations.  \\n\\nEvery interaction we have is fresh.  \\n\\nIf you need to store data, you'll need to use an external tool or service.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 70, 'total_tokens': 120, 'completion_time': 0.090909091, 'prompt_time': 0.003823581, 'queue_time': 0.110798257, 'total_time': 0.094732672}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1abe7299-1c7e-44aa-9223-e875b9c513c2-0', usage_metadata={'input_tokens': 70, 'output_tokens': 50, 'total_tokens': 120})"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([HumanMessage(content=\"Can you store my data temporarily?\")], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are D9, a user interacting with me, an AI assistant. ðŸ¤–  \\n\\nIs there anything else you'd like to know or do?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 132, 'total_tokens': 167, 'completion_time': 0.063636364, 'prompt_time': 0.005729556, 'queue_time': 0.110371989, 'total_time': 0.06936592}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d5b62d97-5446-483b-a3e0-c143bc654f63-0', usage_metadata={'input_tokens': 132, 'output_tokens': 35, 'total_tokens': 167})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([HumanMessage(content=\"who am I?\")], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80}), HumanMessage(content='I am working on Agentic AI.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCould you tell me a bit more about what you're working on specifically? For example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, embodied agents, multi-agent systems)\\n* **What tasks are these agents designed to perform?** (e.g., planning, decision-making, interacting with the environment)\\n* **What are some of the challenges you're facing in your work?**\\n\\nI'm eager to learn more about your project!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 96, 'total_tokens': 221, 'completion_time': 0.227272727, 'prompt_time': 0.005262967, 'queue_time': 0.11001534599999999, 'total_time': 0.232535694}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81f1f30c-f6d6-469a-9d85-cb878beb1c6a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 125, 'total_tokens': 221}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on our conversation, you are Darshan, a data scientist working on Agentic AI. \\n\\nIs there anything else you'd like to tell me about yourself? I'm always happy to learn more. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 233, 'total_tokens': 283, 'completion_time': 0.090909091, 'prompt_time': 0.009079018, 'queue_time': 0.093239002, 'total_time': 0.099988109}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7992496-1245-4c70-83f3-094cf0c923ad-0', usage_metadata={'input_tokens': 233, 'output_tokens': 50, 'total_tokens': 283})]),\n",
       " 'd8': InMemoryChatMessageHistory(messages=[HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I don't have personal experiences or memories, so I don't know who you are.\\n\\nTo help me understand, could you tell me a little about yourself? For example:\\n\\n* What are your hobbies?\\n* What do you like to do in your free time?\\n* What are you interested in learning more about?\\n\\n\\nI'm here to chat and help in any way I can! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 13, 'total_tokens': 105, 'completion_time': 0.167272727, 'prompt_time': 0.001887626, 'queue_time': 0.083940956, 'total_time': 0.169160353}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-24195883-91b7-41c3-9125-38fadbbdde57-0', usage_metadata={'input_tokens': 13, 'output_tokens': 92, 'total_tokens': 105}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question! \\n\\nSince I don't have access to personal information about you, I can't tell you who you are.  \\n\\nBut I can help you explore that question!  \\n\\n* **What makes you feel most like yourself?** \\n* **What are some things you're proud of?**\\n* **What are your values and beliefs?**\\n* **What do you want to be remembered for?**\\n\\nThinking about these things might help you discover more about who you are. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 117, 'total_tokens': 233, 'completion_time': 0.210909091, 'prompt_time': 0.005292857, 'queue_time': 0.093278594, 'total_time': 0.216201948}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-eede2b55-5071-4718-991d-9c7fd674c871-0', usage_metadata={'input_tokens': 117, 'output_tokens': 116, 'total_tokens': 233})]),\n",
       " 'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is D9', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello D9! ðŸ‘‹  How can I help you? ðŸ˜Š  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 38, 'total_tokens': 55, 'completion_time': 0.030909091, 'prompt_time': 0.002340775, 'queue_time': 0.109476953, 'total_time': 0.033249866}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-16e61aca-bbcc-461b-b60b-febadf43eadc-0', usage_metadata={'input_tokens': 38, 'output_tokens': 17, 'total_tokens': 55}), HumanMessage(content='Can you store my data temporarily?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a text-only AI, I don't have memory of past conversations.  \\n\\nEvery interaction we have is fresh.  \\n\\nIf you need to store data, you'll need to use an external tool or service.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 70, 'total_tokens': 120, 'completion_time': 0.090909091, 'prompt_time': 0.003823581, 'queue_time': 0.110798257, 'total_time': 0.094732672}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1abe7299-1c7e-44aa-9223-e875b9c513c2-0', usage_metadata={'input_tokens': 70, 'output_tokens': 50, 'total_tokens': 120}), HumanMessage(content='who am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are D9, a user interacting with me, an AI assistant. ðŸ¤–  \\n\\nIs there anything else you'd like to know or do?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 132, 'total_tokens': 167, 'completion_time': 0.063636364, 'prompt_time': 0.005729556, 'queue_time': 0.110371989, 'total_time': 0.06936592}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d5b62d97-5446-483b-a3e0-c143bc654f63-0', usage_metadata={'input_tokens': 132, 'output_tokens': 35, 'total_tokens': 167})])}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt template 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an intelligent AI assistent. You ahve to answer the user query accurately and in the mentioned {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "new_chain = prompt_2|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I am Gemma, an open-weights AI assistant.\\n\\nI can process and generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\\n\\nMy knowledge is based on the massive dataset I was trained on, but I don't have access to real-time information or Google Search.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 36, 'total_tokens': 107, 'completion_time': 0.129090909, 'prompt_time': 0.002379025, 'queue_time': 0.084103011, 'total_time': 0.131469934}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3c73344b-44c5-41d9-b2d6-4e026e930408-0', usage_metadata={'input_tokens': 36, 'output_tokens': 71, 'total_tokens': 107})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"tell me about you\")], \"language\": \"Gujarati\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new chain into runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
    "# The parameter input_messages_key=\"messages\" tells the runnable which key in the input dictionary contains the chat messages to use for the session history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Agentic AI refers to AI systems designed to act autonomously and make decisions to achieve specific goals. \\n\\nYou're on the right track with your training! \\n\\n\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"session_id\": \"chat2\"}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"I an D9 and I am mastering Agentic AI\")], \"language\":\"Gujarati\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80}), HumanMessage(content='I am working on Agentic AI.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCould you tell me a bit more about what you're working on specifically? For example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, embodied agents, multi-agent systems)\\n* **What tasks are these agents designed to perform?** (e.g., planning, decision-making, interacting with the environment)\\n* **What are some of the challenges you're facing in your work?**\\n\\nI'm eager to learn more about your project!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 96, 'total_tokens': 221, 'completion_time': 0.227272727, 'prompt_time': 0.005262967, 'queue_time': 0.11001534599999999, 'total_time': 0.232535694}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81f1f30c-f6d6-469a-9d85-cb878beb1c6a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 125, 'total_tokens': 221}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on our conversation, you are Darshan, a data scientist working on Agentic AI. \\n\\nIs there anything else you'd like to tell me about yourself? I'm always happy to learn more. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 233, 'total_tokens': 283, 'completion_time': 0.090909091, 'prompt_time': 0.009079018, 'queue_time': 0.093239002, 'total_time': 0.099988109}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7992496-1245-4c70-83f3-094cf0c923ad-0', usage_metadata={'input_tokens': 233, 'output_tokens': 50, 'total_tokens': 283})]),\n",
       " 'd8': InMemoryChatMessageHistory(messages=[HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I don't have personal experiences or memories, so I don't know who you are.\\n\\nTo help me understand, could you tell me a little about yourself? For example:\\n\\n* What are your hobbies?\\n* What do you like to do in your free time?\\n* What are you interested in learning more about?\\n\\n\\nI'm here to chat and help in any way I can! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 13, 'total_tokens': 105, 'completion_time': 0.167272727, 'prompt_time': 0.001887626, 'queue_time': 0.083940956, 'total_time': 0.169160353}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-24195883-91b7-41c3-9125-38fadbbdde57-0', usage_metadata={'input_tokens': 13, 'output_tokens': 92, 'total_tokens': 105}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question! \\n\\nSince I don't have access to personal information about you, I can't tell you who you are.  \\n\\nBut I can help you explore that question!  \\n\\n* **What makes you feel most like yourself?** \\n* **What are some things you're proud of?**\\n* **What are your values and beliefs?**\\n* **What do you want to be remembered for?**\\n\\nThinking about these things might help you discover more about who you are. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 117, 'total_tokens': 233, 'completion_time': 0.210909091, 'prompt_time': 0.005292857, 'queue_time': 0.093278594, 'total_time': 0.216201948}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-eede2b55-5071-4718-991d-9c7fd674c871-0', usage_metadata={'input_tokens': 117, 'output_tokens': 116, 'total_tokens': 233})]),\n",
       " 'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is D9', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello D9! ðŸ‘‹  How can I help you? ðŸ˜Š  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 38, 'total_tokens': 55, 'completion_time': 0.030909091, 'prompt_time': 0.002340775, 'queue_time': 0.109476953, 'total_time': 0.033249866}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-16e61aca-bbcc-461b-b60b-febadf43eadc-0', usage_metadata={'input_tokens': 38, 'output_tokens': 17, 'total_tokens': 55}), HumanMessage(content='Can you store my data temporarily?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a text-only AI, I don't have memory of past conversations.  \\n\\nEvery interaction we have is fresh.  \\n\\nIf you need to store data, you'll need to use an external tool or service.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 70, 'total_tokens': 120, 'completion_time': 0.090909091, 'prompt_time': 0.003823581, 'queue_time': 0.110798257, 'total_time': 0.094732672}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1abe7299-1c7e-44aa-9223-e875b9c513c2-0', usage_metadata={'input_tokens': 70, 'output_tokens': 50, 'total_tokens': 120}), HumanMessage(content='who am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are D9, a user interacting with me, an AI assistant. ðŸ¤–  \\n\\nIs there anything else you'd like to know or do?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 132, 'total_tokens': 167, 'completion_time': 0.063636364, 'prompt_time': 0.005729556, 'queue_time': 0.110371989, 'total_time': 0.06936592}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d5b62d97-5446-483b-a3e0-c143bc654f63-0', usage_metadata={'input_tokens': 132, 'output_tokens': 35, 'total_tokens': 167})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='I an D9 and I am mastering Agentic AI', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Agentic AI refers to AI systems designed to act autonomously and make decisions to achieve specific goals. \\n\\nYou're on the right track with your training! \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 43, 'total_tokens': 81, 'completion_time': 0.069090909, 'prompt_time': 0.002587564, 'queue_time': 0.09212137199999999, 'total_time': 0.071678473}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-72b15d16-fca2-4af8-bbf8-32c8ceb82a63-0', usage_metadata={'input_tokens': 43, 'output_tokens': 38, 'total_tokens': 81})])}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing the Conversation History\n",
    "What if our chat history will become huge???\n",
    "\n",
    "Trimming\n",
    "\n",
    "\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer=trim_messages(\n",
    "    max_tokens=30,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\")| trimmer)| prompt_2 | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnablePassthrough is a simple runnable that applies a transformation pipeline to its input without managing additional state, while \n",
    "\n",
    "RunnableWithMessageHistory extends a runnable by automatically handling chat history. The latter retrieves and updates session-specific messages, ensuring that conversational context is maintained during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't know your personal preferences!  \\n\\nTo figure out your favorite ice cream, think about:\\n\\n* **What flavors do you usually go for?** Chocolate, vanilla, fruity, something more unique?\\n* **What textures do you like?** Creamy, chunky, something with swirls?\\n* **Are there any toppings you can't resist?** Sprinkles, nuts, whipped cream? \\n\\n\\nLet me know if you want to brainstorm some ideas! ðŸ˜ŠðŸ¨ \\n\\n\""
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"Who ice creame do I like?\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat bot\n",
    "Let's connect everything together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer=trim_messages(\n",
    "    max_tokens=30,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\"session_id\": \"d9\"} wrong..\n",
    "config = {\"configurable\": {\"session_id\": \"d9\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = store[config[\"configurable\"][\"session_id\"]].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80}), HumanMessage(content='I am working on Agentic AI.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCould you tell me a bit more about what you're working on specifically? For example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, embodied agents, multi-agent systems)\\n* **What tasks are these agents designed to perform?** (e.g., planning, decision-making, interacting with the environment)\\n* **What are some of the challenges you're facing in your work?**\\n\\nI'm eager to learn more about your project!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 96, 'total_tokens': 221, 'completion_time': 0.227272727, 'prompt_time': 0.005262967, 'queue_time': 0.11001534599999999, 'total_time': 0.232535694}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81f1f30c-f6d6-469a-9d85-cb878beb1c6a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 125, 'total_tokens': 221}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on our conversation, you are Darshan, a data scientist working on Agentic AI. \\n\\nIs there anything else you'd like to tell me about yourself? I'm always happy to learn more. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 233, 'total_tokens': 283, 'completion_time': 0.090909091, 'prompt_time': 0.009079018, 'queue_time': 0.093239002, 'total_time': 0.099988109}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7992496-1245-4c70-83f3-094cf0c923ad-0', usage_metadata={'input_tokens': 233, 'output_tokens': 50, 'total_tokens': 283})]),\n",
       " 'd8': InMemoryChatMessageHistory(messages=[HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I don't have personal experiences or memories, so I don't know who you are.\\n\\nTo help me understand, could you tell me a little about yourself? For example:\\n\\n* What are your hobbies?\\n* What do you like to do in your free time?\\n* What are you interested in learning more about?\\n\\n\\nI'm here to chat and help in any way I can! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 13, 'total_tokens': 105, 'completion_time': 0.167272727, 'prompt_time': 0.001887626, 'queue_time': 0.083940956, 'total_time': 0.169160353}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-24195883-91b7-41c3-9125-38fadbbdde57-0', usage_metadata={'input_tokens': 13, 'output_tokens': 92, 'total_tokens': 105}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question! \\n\\nSince I don't have access to personal information about you, I can't tell you who you are.  \\n\\nBut I can help you explore that question!  \\n\\n* **What makes you feel most like yourself?** \\n* **What are some things you're proud of?**\\n* **What are your values and beliefs?**\\n* **What do you want to be remembered for?**\\n\\nThinking about these things might help you discover more about who you are. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 117, 'total_tokens': 233, 'completion_time': 0.210909091, 'prompt_time': 0.005292857, 'queue_time': 0.093278594, 'total_time': 0.216201948}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-eede2b55-5071-4718-991d-9c7fd674c871-0', usage_metadata={'input_tokens': 117, 'output_tokens': 116, 'total_tokens': 233})]),\n",
       " 'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is D9', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello D9! ðŸ‘‹  How can I help you? ðŸ˜Š  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 38, 'total_tokens': 55, 'completion_time': 0.030909091, 'prompt_time': 0.002340775, 'queue_time': 0.109476953, 'total_time': 0.033249866}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-16e61aca-bbcc-461b-b60b-febadf43eadc-0', usage_metadata={'input_tokens': 38, 'output_tokens': 17, 'total_tokens': 55}), HumanMessage(content='Can you store my data temporarily?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a text-only AI, I don't have memory of past conversations.  \\n\\nEvery interaction we have is fresh.  \\n\\nIf you need to store data, you'll need to use an external tool or service.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 70, 'total_tokens': 120, 'completion_time': 0.090909091, 'prompt_time': 0.003823581, 'queue_time': 0.110798257, 'total_time': 0.094732672}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1abe7299-1c7e-44aa-9223-e875b9c513c2-0', usage_metadata={'input_tokens': 70, 'output_tokens': 50, 'total_tokens': 120}), HumanMessage(content='who am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are D9, a user interacting with me, an AI assistant. ðŸ¤–  \\n\\nIs there anything else you'd like to know or do?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 132, 'total_tokens': 167, 'completion_time': 0.063636364, 'prompt_time': 0.005729556, 'queue_time': 0.110371989, 'total_time': 0.06936592}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d5b62d97-5446-483b-a3e0-c143bc654f63-0', usage_metadata={'input_tokens': 132, 'output_tokens': 35, 'total_tokens': 167})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='I an D9 and I am mastering Agentic AI', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Agentic AI refers to AI systems designed to act autonomously and make decisions to achieve specific goals. \\n\\nYou're on the right track with your training! \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 43, 'total_tokens': 81, 'completion_time': 0.069090909, 'prompt_time': 0.002587564, 'queue_time': 0.09212137199999999, 'total_time': 0.071678473}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-72b15d16-fca2-4af8-bbf8-32c8ceb82a63-0', usage_metadata={'input_tokens': 43, 'output_tokens': 38, 'total_tokens': 81})])}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hi Darshan,\\n\\nIt's nice to meet you!  I'm Gemma, an AI assistant.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people use data to solve problems and uncover insights.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002106825, 'queue_time': 0.09164919299999999, 'total_time': 0.109379552}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-457b4b0c-bbe8-4644-a483-919d1b05bd60-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80}),\n",
       " HumanMessage(content='I am working on Agentic AI.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCould you tell me a bit more about what you're working on specifically? For example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, embodied agents, multi-agent systems)\\n* **What tasks are these agents designed to perform?** (e.g., planning, decision-making, interacting with the environment)\\n* **What are some of the challenges you're facing in your work?**\\n\\nI'm eager to learn more about your project!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 96, 'total_tokens': 221, 'completion_time': 0.227272727, 'prompt_time': 0.005262967, 'queue_time': 0.11001534599999999, 'total_time': 0.232535694}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81f1f30c-f6d6-469a-9d85-cb878beb1c6a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 125, 'total_tokens': 221}),\n",
       " HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Based on our conversation, you are Darshan, a data scientist working on Agentic AI. \\n\\nIs there anything else you'd like to tell me about yourself? I'm always happy to learn more. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 233, 'total_tokens': 283, 'completion_time': 0.090909091, 'prompt_time': 0.009079018, 'queue_time': 0.093239002, 'total_time': 0.099988109}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7992496-1245-4c70-83f3-094cf0c923ad-0', usage_metadata={'input_tokens': 233, 'output_tokens': 50, 'total_tokens': 283})]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\")| trimmer)| prompt | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'session_id': 'd9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I have no memory of past interactions and no information about you.  To tell you about yourself, I need you to tell me something! ðŸ˜Š  \\n\\nWhat would you like to share? \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 37, 'total_tokens': 84, 'completion_time': 0.085454545, 'prompt_time': 0.002351415, 'queue_time': 0.06638585300000001, 'total_time': 0.08780596}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-58dccd99-ba71-43c1-b30e-3ff9774037b6-0', usage_metadata={'input_tokens': 37, 'output_tokens': 47, 'total_tokens': 84})"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"messages\" : [HumanMessage(content=\"Tell me about me?\")]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's great!  \\n\\nAgentic AI focuses on creating AI systems that can act autonomously and make decisions to achieve goals.  \\n\\nTo master it, you'll want to delve into:\\n\\n* **Goal-oriented programming:** Teaching AI to understand and pursue specific objectives.\\n* **Decision-making algorithms:** Exploring how AI weighs options and chooses actions.\\n* **Learning and adaptation:** Enabling AI to improve its performance through experience.\\n* **Robotics and control:** Applying agentic AI to physical systems.\\n\\n\\nGood luck with your studies! \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 43, 'total_tokens': 161, 'completion_time': 0.214545455, 'prompt_time': 0.002572584, 'queue_time': 0.092012728, 'total_time': 0.217118039}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-cf1063ee-ba11-4fbf-bbef-fdb9b318cdb9-0', usage_metadata={'input_tokens': 43, 'output_tokens': 118, 'total_tokens': 161})"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"messages\" : [HumanMessage(content=\"I an D9 and I am mastering Agentic AI\")]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am Gemma, an open-weights AI assistant. I can generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way. I am still under development, but I have learned to perform many kinds of tasks.  \\n\\nAsk me anything!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 37, 'total_tokens': 98, 'completion_time': 0.110909091, 'prompt_time': 0.002382164, 'queue_time': 0.10891774, 'total_time': 0.113291255}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-afdc089d-0968-451e-86fc-8d82f809eb69-0', usage_metadata={'input_tokens': 37, 'output_tokens': 61, 'total_tokens': 98})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"messages\" : [HumanMessage(content=\"tell me about you?\")]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I have no information about you. I am a new, large language model.  \\n\\nTo tell me about yourself, you can ask me questions or provide information. ðŸ˜Š  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 37, 'total_tokens': 80, 'completion_time': 0.078181818, 'prompt_time': 0.002348815, 'queue_time': 0.10897936899999999, 'total_time': 0.080530633}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0a645c27-0763-4d28-801d-b3e30efe1f4d-0', usage_metadata={'input_tokens': 37, 'output_tokens': 43, 'total_tokens': 80})"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"messages\" : [HumanMessage(content=\"Tell me about me?\")]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "trimming = RunnablePassthrough.assign(messages = itemgetter(\"messages\")| trimmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
