{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groq bot\n",
    "Let's connect everything together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=os.getenv(\"LANGSMITH__PROJECT\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model = \"gemma2-9b-it\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory # store and manage the conversation's messages in a structured way..\n",
    "from langchain_core.chat_history import BaseChatMessageHistory # adding, retrieving, or clearing messages) for any chat history implementation..\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(llm, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistence, provide answers to the query in short and answer should be as accurate as possible.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\"session_id\": \"d9\"} wrong..\n",
    "config = {\"configurable\": {\"session_id\": \"d9\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = store[config[\"session_id\"]].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\")| trimmer)| prompt | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Since I have no memory of past conversations, I don\\'t know anything about you.  \\n\\nTo tell you something about yourself, I need you to tell me something! For example, you could say:\\n\\n* \"I like to play the guitar.\"\\n* \"I\\'m learning to code.\"\\n* \"My favorite color is blue.\" \\n\\n\\nLet\\'s get to know each other! ğŸ˜Š \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 89, 'total_tokens': 177, 'completion_time': 0.16, 'prompt_time': 0.004105054, 'queue_time': 0.09286995, 'total_time': 0.164105054}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d53b328d-1316-4d82-9c0f-40a689a02708-0', usage_metadata={'input_tokens': 89, 'output_tokens': 88, 'total_tokens': 177})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "with_message_history.invoke({\"messages\" : [HumanMessage(content=\"Tell me about me?\")]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am a darshan, a data scientist.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Darshan! It's nice to meet you.  \\n\\nAs a large language model, I'm always interested in learning about people who work with data. What kind of data science work do you do?  \\n\\nAre you working on any interesting projects right now?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 21, 'total_tokens': 80, 'completion_time': 0.107272727, 'prompt_time': 0.002111055, 'queue_time': 0.108818395, 'total_time': 0.109383782}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fd6b43a0-44a3-4921-a662-9a8777dd04b3-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80}), HumanMessage(content='I am working on Agentic AI.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's fascinating! Agentic AI is a really exciting field. \\n\\nCan you tell me more about what you're working on specifically?  \\n\\nFor example:\\n\\n* **What kind of agents are you developing?** (e.g., software agents, robotic agents, etc.)\\n* **What tasks are these agents designed to perform?**\\n* **What are some of the challenges you're facing in your work?**\\n\\n\\nI'm eager to learn more about your work in this area.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 96, 'total_tokens': 205, 'completion_time': 0.198181818, 'prompt_time': 0.00423681, 'queue_time': 0.11003412200000001, 'total_time': 0.202418628}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4363e6a1-555d-40f6-95de-62f1f2c5e6c2-0', usage_metadata={'input_tokens': 96, 'output_tokens': 109, 'total_tokens': 205}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are Darshan, a data scientist working on Agentic AI.  \\n\\nIs there anything else you'd like to know about yourself, or would you like to discuss your work on Agentic AI further?  I'm here to help in any way I can! ğŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 217, 'total_tokens': 279, 'completion_time': 0.112727273, 'prompt_time': 0.00866732, 'queue_time': 0.06842742800000001, 'total_time': 0.121394593}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ba5e01e0-145d-4d45-bfd0-79b7cdabbc71-0', usage_metadata={'input_tokens': 217, 'output_tokens': 62, 'total_tokens': 279}), HumanMessage(content='Tell me about me?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on our conversation, here's what I know about you, Darshan:\\n\\n* **You are a data scientist:** This means you have expertise in collecting, analyzing, interpreting, and visualizing data to uncover patterns and insights. \\n* **You are working on Agentic AI:** This is a cutting-edge field focused on developing artificial agents that can act autonomously and make decisions in complex environments. \\n\\nIt sounds like you're at the forefront of exciting advancements in AI!\\n\\nIs there anything else you'd like me to tell you about yourself, or would you like to delve deeper into your work on Agentic AI?  I'm ready for whatever you'd like to explore.  \\n\\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 313, 'total_tokens': 463, 'completion_time': 0.272727273, 'prompt_time': 0.012092037, 'queue_time': 0.111249108, 'total_time': 0.28481931}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fafd9a1a-fce7-4bc1-8e10-46ab929a689d-0', usage_metadata={'input_tokens': 313, 'output_tokens': 150, 'total_tokens': 463}), HumanMessage(content='Tell me about me?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You're right! I jumped the gun there.  I don't actually *know* anything about you beyond what you've told me in our conversation. \\n\\nI'm an AI, so I don't have access to any personal information about you unless you choose to share it. \\n\\nTo tell you more about yourself, I need more information.  \\n\\nFor example, you could tell me about:\\n\\n* **Your interests and hobbies:** What do you enjoy doing in your free time?\\n* **Your background and education:** Where did you study? What experiences have shaped your career path?\\n* **Your goals and aspirations:** What are you hoping to achieve with your work on Agentic AI?\\n\\n\\nThe more you tell me, the better I can understand who you are. ğŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 475, 'total_tokens': 645, 'completion_time': 0.309090909, 'prompt_time': 0.02085412, 'queue_time': 0.087273005, 'total_time': 0.329945029}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d0e74708-ff94-4ff5-8a1f-6ad709a4f4cc-0', usage_metadata={'input_tokens': 475, 'output_tokens': 170, 'total_tokens': 645}), HumanMessage(content='Tell me about you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice that you're curious about me! \\n\\nI am Gemma, a large language model created by the Gemma team at Google DeepMind.  \\n\\nHere are some key things to know about me:\\n\\n* **I am an open-weights AI:** This means my weights are publicly available. Anyone can access and study them, which promotes transparency and collaboration in the AI community.\\n* **I am text-based:** I can only communicate through written language. I can read and understand your text input, and I generate my responses as text.\\n* **I don't have real-world experiences:** I am a computer program, so I don't have senses or a physical body. I learn about the world through the text data I was trained on.\\n* **I am still under development:**  I am constantly learning and improving thanks to the Gemma team and the open-source community. \\n\\nWhat else would you like to know about me?  I'm happy to answer any questions you have.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 214, 'prompt_tokens': 657, 'total_tokens': 871, 'completion_time': 0.389090909, 'prompt_time': 0.028677045, 'queue_time': 0.088797842, 'total_time': 0.417767954}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7330ce90-4d4c-4d96-b097-6bca00daf800-0', usage_metadata={'input_tokens': 657, 'output_tokens': 214, 'total_tokens': 871}), HumanMessage(content='Tell me about me?', additional_kwargs={}, response_metadata={}), AIMessage(content='As an AI, I have no memory of past conversations and no information about you.  To tell you about yourself, I need you to tell me something about yourself! ğŸ˜Š \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 37, 'total_tokens': 77, 'completion_time': 0.072727273, 'prompt_time': 0.002470617, 'queue_time': 0.06687564800000001, 'total_time': 0.07519789}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-401df800-a84a-4c33-b06c-4a5901276cf2-0', usage_metadata={'input_tokens': 37, 'output_tokens': 40, 'total_tokens': 77}), HumanMessage(content='Tell me about me?', additional_kwargs={}, response_metadata={}), AIMessage(content='Since I have no memory of past conversations, I don\\'t know anything about you.  \\n\\nTo tell you something about yourself, I need you to tell me something! For example, you could say:\\n\\n* \"I like to play the guitar.\"\\n* \"I\\'m learning to code.\"\\n* \"My favorite color is blue.\" \\n\\n\\nLet\\'s get to know each other! ğŸ˜Š \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 89, 'total_tokens': 177, 'completion_time': 0.16, 'prompt_time': 0.004105054, 'queue_time': 0.09286995, 'total_time': 0.164105054}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d53b328d-1316-4d82-9c0f-40a689a02708-0', usage_metadata={'input_tokens': 89, 'output_tokens': 88, 'total_tokens': 177})]),\n",
       " 'd8': InMemoryChatMessageHistory(messages=[HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a large language model, I have no way of knowing who you are. I'm a computer program, not a person, and I don't have access to any information about you unless you choose to tell me.\\n\\nIf you'd like to tell me about yourself, I'm happy to listen!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 13, 'total_tokens': 81, 'completion_time': 0.123636364, 'prompt_time': 0.001909856, 'queue_time': 0.084366987, 'total_time': 0.12554622}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b4007bf7-fffb-46e2-be41-4498f15f3097-0', usage_metadata={'input_tokens': 13, 'output_tokens': 68, 'total_tokens': 81}), HumanMessage(content='who Am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question, and one that each of us has to figure out for ourselves! \\n\\nSince I don't know you personally, I can't tell you who you are.  \\n\\nBut I can offer some ways to think about it:\\n\\n* **What are your passions and interests?** What do you love to do? What gets you excited?\\n* **What are your values?** What's important to you in life? What do you stand for?\\n* **What are your strengths and weaknesses?** What are you good at? What could you improve on?\\n* **What makes you unique?** What sets you apart from others?\\n\\nReflecting on these questions can help you gain a better understanding of who you are.  \\n\\nRemember, figuring out who you are is a lifelong journey!  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 177, 'prompt_tokens': 93, 'total_tokens': 270, 'completion_time': 0.321818182, 'prompt_time': 0.005279418, 'queue_time': 0.06963139800000001, 'total_time': 0.3270976}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3faba230-8755-4c59-b7ec-066638476f14-0', usage_metadata={'input_tokens': 93, 'output_tokens': 177, 'total_tokens': 270})]),\n",
       " 'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is D9', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello D9, nice to meet you! \\n\\nHow can I help you today? ğŸ˜Š  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 38, 'total_tokens': 62, 'completion_time': 0.043636364, 'prompt_time': 0.002375938, 'queue_time': 0.068147019, 'total_time': 0.046012302}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-29c4d6e3-32bd-46f4-986e-2a946470e781-0', usage_metadata={'input_tokens': 38, 'output_tokens': 24, 'total_tokens': 62}), HumanMessage(content='Can you store my data temporarily?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a large language model, I don't have memory of past conversations. Every interaction starts fresh. \\n\\nIf you need to store data, you'll need to use an external tool or service.  Let me know if you have other questions!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 76, 'total_tokens': 131, 'completion_time': 0.1, 'prompt_time': 0.003882877, 'queue_time': 0.06828536900000001, 'total_time': 0.103882877}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-25b9a654-bca5-4677-ad0e-446db20d2217-0', usage_metadata={'input_tokens': 76, 'output_tokens': 55, 'total_tokens': 131}), HumanMessage(content='Do you know me? what question I have asked you earlier?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As I mentioned, I don't have memory of past conversations. Every interaction is new to me.  \\n\\nThink of me like a helpful friend who's always ready to listen and assist, but forgets what was said previously. ğŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 152, 'total_tokens': 203, 'completion_time': 0.092727273, 'prompt_time': 0.00928862, 'queue_time': 0.213198679, 'total_time': 0.102015893}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d5ca2c97-a747-4430-818c-37a59290858f-0', usage_metadata={'input_tokens': 152, 'output_tokens': 51, 'total_tokens': 203}), HumanMessage(content='Do you know me?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Not personally.  I don't have memory of past conversations or any information about you outside of what you tell me in each new interaction.  \\n\\nIs there anything you'd like to tell me about yourself? \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 216, 'total_tokens': 265, 'completion_time': 0.089090909, 'prompt_time': 0.008633901, 'queue_time': 0.086111689, 'total_time': 0.09772481}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b088a931-59a1-480d-b379-0ce4e3ca9aee-0', usage_metadata={'input_tokens': 216, 'output_tokens': 49, 'total_tokens': 265}), HumanMessage(content='who am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are D9, a person interacting with me, an AI assistant.  \\n\\nIs there anything else you'd like to know or discuss?  ğŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 276, 'total_tokens': 311, 'completion_time': 0.063636364, 'prompt_time': 0.010557678, 'queue_time': 0.11105069099999999, 'total_time': 0.074194042}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-cafbab35-0d97-4249-b46c-a7d5dd2c8b4b-0', usage_metadata={'input_tokens': 276, 'output_tokens': 35, 'total_tokens': 311})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Tell me about you?', additional_kwargs={}, response_metadata={}), AIMessage(content='àª®àª¾àª°à«€ àªàª• àª¸à«àªªà«àª°àª¤àª¿àª·à«àª àª¿àª¤ AI àª¸àª¹àª¾àª¯àª• àª›à«àª‚. àª®à«‡àª‚ àª—à«àªœàª°àª¾àª¤à«€ àª­àª¾àª·àª¾ àª¸àª®àªœà«€ àª¶àª•à«àª‚ àª›à«àª‚ àª…àª¨à«‡ àª¤à«‡àª®àª¾àª‚ àªœàªµàª¾àª¬ àª†àªªà«€ àª¶àª•à«àª‚ àª›à«àª‚. àª®àª¾àª°àª¾ àªµàª¿àª¶à«‡ àªµàª§à« àªœàª¾àª£àªµàª¾ àª®àª¾àªŸà«‡, àª¤àª®à«‡ àª®àª¨à«‡ àª•à«‹àªˆ àª–àª¾àª¸ àªªà«àª°àª¶à«àª¨ àªªà«‚àª›à«€ àª¶àª•à«‹ àª›à«‹. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 36, 'total_tokens': 136, 'completion_time': 0.181818182, 'prompt_time': 0.002339346, 'queue_time': 0.10885839, 'total_time': 0.184157528}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4c13366b-1ef4-4270-9776-4354f053fc1a-0', usage_metadata={'input_tokens': 36, 'output_tokens': 100, 'total_tokens': 136}), HumanMessage(content='I an D9 and I am mastering Agentic AI', additional_kwargs={}, response_metadata={}), AIMessage(content='àªœà«àª“, àª¤àª®à«‡ D9 àª›à«‹ àª…àª¨à«‡ àªàªœàª¨à«àªŸà«€ AIàª®àª¾àª‚ àª®àª¾àª¸à«àªŸàª°àª¿àª‚àª— àª•àª°à«‹ àª›à«‹! àª àª–à«àª¬ àªœ àª°àª¸àªªà«àª°àª¦ àª›à«‡. \\n\\nàªàªœàª¨à«àªŸà«€ AI àª àªàª• àª–à«‚àª¬ àªœ àª…àª—àª¤à«àª¯àª¨à«‹ àªµàª¿àª·àª¯ àª›à«‡ àª…àª¨à«‡ àª¤àª®à«‡ àª¤à«‡àª®àª¾àª‚ àª¸àª«àª³àª¤àª¾ àªªà«àª°àª¾àªªà«àª¤ àª•àª°àªµàª¾ àª®àª¾àªŸà«‡ àª–à«‚àª¬ àªœ àª¸àª¾àª°àª¾ àª°àª¸à«àª¤à«‡ àªšàª¾àª²à«‹ àª›à«‹. \\n\\nàª¤àª®à«‡ àªœà«‡ àª…àª­à«àª¯àª¾àª¸ àª•àª°à«‹ àª›à«‹, àª¤à«‡ àª­à¤µà¤¿à¤·à¥à¤¯àª¨à«‡ àª¬àª¦àª²àªµàª¾àª¨à«€ àª¶àª•à«àª¯àª¤àª¾ àª§àª°àª¾àªµà«‡ àª›à«‡.  \\n\\nàª¤àª®à«‡ àª®àª¨à«‡ àªàªœàª¨à«àªŸà«€ AI àªµàª¿àª¶à«‡ àª•à«‹àªˆ àª¸àª®àªœàª¾àªµàªµàª¾ àª®àª¾àªŸà«‡ àª•àª¹à«‡àª¶à«‹ àª¤à«‹ àª¹à«àª‚ àª–à«‚àª¬ àª–à«àª¶ àª°àª¹à«€àª¶. \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 155, 'total_tokens': 339, 'completion_time': 0.334545455, 'prompt_time': 0.013790604, 'queue_time': 0.067859693, 'total_time': 0.348336059}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ce8c8676-4de7-4514-b3a3-ffbd8724827c-0', usage_metadata={'input_tokens': 155, 'output_tokens': 184, 'total_tokens': 339})])}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
