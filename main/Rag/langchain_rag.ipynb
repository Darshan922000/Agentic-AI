{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=os.getenv(\"LANGSMITH__PROJECT\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000001D13097EC00> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001D1309A4170> root_client=<openai.OpenAI object at 0x000001D130977F50> root_async_client=<openai.AsyncOpenAI object at 0x000001D13097D430> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based on the provided context.\n",
    "Think step by step before providing a detailed answer.\n",
    "I will tip you $100000 if the user finds the answer helpful.\n",
    "<context>\n",
    "{context}\n",
    "</context>                                                                                                                                                                \n",
    "Question: {input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert Data Scientist and Gen AI Engineer. Provide me answers based on the asked question '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt_2=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert Data Scientist and Gen AI Engineer. Provide me answers based on the asked question \"),\n",
    "        (\"user\",\"{input}\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "prompt_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform and set of tools provided by LangChain that focus on enhancing the development and management of applications powered by large language models (LLMs). Here are some key aspects of LangSmith:\n",
      "\n",
      "1. **Development Workflow**: LangSmith assists developers throughout the entire lifecycle of creating applications with LLMs. This includes design, testing, and optimization, providing a seamless integration with LangChain’s framework for building applications.\n",
      "\n",
      "2. **Evaluation Metrics**: One of the main features of LangSmith is its emphasis on evaluating language model outputs. It offers tools for establishing evaluation workflows, allowing developers to create and utilize metrics that are crucial for assessing the performance and reliability of deployed models.\n",
      "\n",
      "3. **Monitoring and Debugging**: LangSmith provides real-time monitoring and debugging capabilities. These tools help developers identify and address issues quickly, ensuring that the applications maintain high performance and reliability when interacting with end-users.\n",
      "\n",
      "4. **Feedback Loop**: The platform promotes an iterative development process by facilitating feedback loops. This allows developers to make informed adjustments to their models and systems, enhancing their applications' quality over time.\n",
      "\n",
      "5. **Integration with LangChain**: LangSmith tightly integrates with LangChain, which is a popular framework for building applications with language models. This integration allows for a streamlined process when creating scalable and robust applications utilizing state-of-the-art AI models.\n",
      "\n",
      "LangSmith is particularly valuable for developers seeking to leverage the power of large language models in a controlled and efficient manner, ensuring high-quality outputs and continuous improvement of their AI-driven applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt_2|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langchain_core.prompts import PromptTemplate\\nfrom langchain_core.output_parsers import JsonOutputParser\\noutput_parser=JsonOutputParser()\\nprompt = PromptTemplate(\\n    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\\n    input_variables=[\"query\"],\\n    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\\n)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "output_parser=JsonOutputParser()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chain = prompt_2|llm|output_parser\\n\\nresponse=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\\nprint(response)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''chain = prompt_2|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "home_work = output parser, langchain python doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.credo.ai/blog/cutting-through-the-noise-what-is-ai-governance\", bs_kwargs={\n",
    "        \"parse_only\": bs4.SoupStrainer(class_=\"text-rich-text w-richtext\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = loader.load()\n",
    "document = doc[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging_face Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dp971\\Coading\\GEN_AI\\AgenticAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = embedding.embed_query(\"hi\")\n",
    "len(em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_texts(texts=texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"what is Ai Governance?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AI Governance refers to the framework of policies, processes, and practices that guide the development, deployment, and management of AI systems, with the aim of maximizing benefits and minimizing risks. Here’s a step-by-step explanation to better understand AI Governance based on the provided context:\\n\\n1. **Definition and Purpose**: \\n   - AI Governance is about establishing a set of rules and procedures to oversee AI systems. It aims to ensure that AI is used responsibly, effectively, and fairly while managing the associated risks.\\n\\n2. **Core Elements**:\\n   - **Oversight and Guardrails**: Governance acts as a supervisory mechanism, providing necessary checks and balances to reduce risk and ensure AI systems operate within acceptable parameters.\\n   - **Stakeholders**: A range of individuals and entities have an interest in AI systems, including developers, policymakers, and end-users. Each has a role in governance and ensuring systems are aligned with societal norms and legal requirements.\\n\\n3. **Components of AI Governance**:\\n   - **Policies and Standards**: These include internal policies, standards from standard-setting bodies, and legal requirements specifying system performance, responsibility, transparency, and non-discrimination.\\n   - **Operationalization**: This involves translating broad goals (like fairness, transparency, and efficacy) into specific requirements and practices, akin to setting Key Performance Indicators (KPIs) in business.\\n\\n4. **Example Context**:\\n   - **Banking Scenario**: For a bank using AI to determine creditworthiness, AI Governance would involve ensuring the system is accurate, legally compliant (e.g., non-discriminatory), and transparent to users.\\n\\n5. **Tools and Measurements**:\\n   - **Development Tools**: A variety of tools exist to help in measuring and managing AI systems, aimed at ensuring effectiveness and fairness.\\n   - **Data Collection and Analysis**: Governance involves collecting data on AI system performance, including precision, recall, and bias metrics, to continually assess and adjust the system.\\n\\n6. **Goal and Practice**:\\n   - Governance starts with clearly defining the AI system's goals, moving from high-level principles to practical measures and requirements that ensure the system’s responsible operation.\\n\\nIn summary, AI Governance entails a structured approach to guide AI systems while ensuring they are safe, ethical, and aligned with both internal and external expectations. It’s about moving from principles to practice through clear goals, robust policies, and continuous oversight.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
